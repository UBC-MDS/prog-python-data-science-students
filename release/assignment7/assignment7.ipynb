{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming in Python for Data Science \n",
    "\n",
    "# Assignment 7: Importing Files and the Coding Style Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Describe what Python libraries are, as well as explain when and why they are useful.\n",
    "- Identify where code can be improved concerning variable names, magic numbers, comments and whitespace.\n",
    "- Write code that is human readable and follows the black style guide.\n",
    "- Import files from other directories.\n",
    "- Use [`pytest`](https://docs.pytest.org/en/stable/) to check a function's tests.\n",
    "- When running [`pytest`](https://docs.pytest.org/en/stable/), explain how pytest finds the associated test functions.\n",
    "- Explain how the Python debugger can help rectify your code.\n",
    "\n",
    "This assignment covers [Module 7](https://prog-learn.mds.ubc.ca/en/module7) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` and the `raise NotImplementedError # No Answer - remove if you provide an answer` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "import test_assignment7 as t\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Importing libraries   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(a)** <br> {points: 1}  \n",
    "\n",
    "Import the `pandas` library and name it `pd` in the worksheet environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7a239b989f8065dc779eac5c0db120",
     "grade": false,
     "grade_id": "cell-33212a70ac92beea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f685f2f8a2ce8ecc6e254989ff98820",
     "grade": true,
     "grade_id": "cell-932eba7b75fc58b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1a(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(b)** <br> {points: 1}  \n",
    "\n",
    "Import the Altair library into the worksheet enviroment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36271cc448c00e70899b7d28563bf9bb",
     "grade": false,
     "grade_id": "cell-2fb5b8e075bbd416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61befda99759541fa776cd5b609d4863",
     "grade": true,
     "grade_id": "cell-eca513c226d7f7f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(c)** <br> {points: 1}  \n",
    "\n",
    "From the `numpy` library, only import the `arange()` function using the keywork `from`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e04a06ede5f30fe883b4bc81409da5a4",
     "grade": false,
     "grade_id": "cell-e99cf81fa9d22012",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a8ebfc54a36aa71ca44dd915c08591d",
     "grade": true,
     "grade_id": "cell-cf28d80fe773f520",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with other files  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(a)** <br> {points: 1}  \n",
    "\n",
    "Load in the `chopped.csv` file from the data folder and save it as an object named `chopped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d5320b231dfcaedd4e56b3582c60daa",
     "grade": false,
     "grade_id": "cell-6134753661931f24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec65ca40ff824242d121b0d208b4070e",
     "grade": true,
     "grade_id": "cell-746bfa633c7af0a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2a(chopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(b)** <br> {points: 1}  \n",
    "\n",
    "Import the the function `sample_dataframe()` (that we created in Assignment 6) from `sampling.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3390bf4c0478081f9033c3610846add3",
     "grade": false,
     "grade_id": "cell-a60b50fcb75443d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cd337866dc4a04621d25f3fbe0ebce2",
     "grade": true,
     "grade_id": "cell-635d330803423f4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(c)** <br> {points: 2}  \n",
    "\n",
    "To refresh yourself on what the function `sample_dataframe()` does, inspect the function docstring.  \n",
    "\n",
    "Which of the following is the correct way to inspect the docstring of the function `sample_dataframe()`?     \n",
    "*Hint: Try it out yourself*\n",
    "\n",
    "A) `?sample.sample_dataframe`\n",
    "\n",
    "B) `?sample.sample_dataframe()` \n",
    "\n",
    "C) `?sample_dataframe`\n",
    "\n",
    "D) `?sample_dataframe()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer2_c`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37ea0df60619ac283eb5e272a0aa8c4",
     "grade": false,
     "grade_id": "cell-7fcb41f86f7ea257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f518f3ab0ad13f24297344e661616fb",
     "grade": true,
     "grade_id": "cell-35291c2eeae630fd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to obtain the function docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(d)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter is optional?       \n",
    "Answer the parameter name as a `str` in the object `answer2_d`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d1ef9c2fe2ed9b7c9d97ecc9146b943",
     "grade": false,
     "grade_id": "cell-e8920e5152e7e308",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_d = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33e02e909283893e74a4671d385864b",
     "grade": true,
     "grade_id": "cell-5821de7729f52862",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2d(answer2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(e)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter accepts data types of `str`?      \n",
    "\n",
    "Answer the parameter name as a `str` in the object `answer2_e`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e24962220dde0237ba12efbd484be1",
     "grade": false,
     "grade_id": "cell-e676311b515dde12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_e = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b425c2b493cee2b74194928aeff2432",
     "grade": true,
     "grade_id": "cell-3fd7084db8d73672",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2e(answer2_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(f)** <br> {points: 1}  \n",
    "\n",
    "Sample two rows from each season from the `chopped` dataframe using your function `sample_dataframe`.     \n",
    "\n",
    "Save this in an object named `chopped_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "882ac872c1be42d6674b60036e238c2c",
     "grade": false,
     "grade_id": "cell-6299480a9da3c466",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped_sample = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec1de9cca0165ef824e2d7bf3b5ac1",
     "grade": true,
     "grade_id": "cell-a3352eba01015292",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_2f(chopped_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Pytest\n",
    "\n",
    "We have provided you with another file called `test_sampling.py` which contains multiple functions that test if our `sample_dataframe()` function is working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(a)** <br> {points: 1}  \n",
    "\n",
    "The tests for `sample_dataframe()` are located in a different file than the function which means we will need to import the function from our `sampling.py` file at the top of `test_sampling.py`. \n",
    "\n",
    "Open `test_sampling.py` and on line 2, write code to import the `sample_dataframe()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cade35fe5e7e6d5bb01615bec546eaa",
     "grade": true,
     "grade_id": "cell-ae85375476286d96",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a179132ad8eb5bbe5f4881b9e1cf29f",
     "grade": false,
     "grade_id": "cell-6b432fa592bfb361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3(b)** <br>\n",
    "\n",
    "We are going to do things a little differently then in the lesson here. \n",
    "Using `pytest` in a jupyter notebook, we can check if all the tests in `test_sampling.py` pass using the code `!pytest test_sampling.py` in a code cell. \n",
    "\n",
    "\n",
    "Try it out in the cell below and answer the following multiple choice questions regarding the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this code chunk to check your tests on the file test_sampling.py using pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-i)** <br> {points: 1}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` passed?      \n",
    "*Assign the correct answer to an object called `tests_passed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "547fbada2f64cffe0d00e10fbe452d9a",
     "grade": false,
     "grade_id": "cell-fb3fd2b5482fdc05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_passed = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b1813b96d691c1eaf9f317d381a525",
     "grade": true,
     "grade_id": "cell-c687047bada4fe95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3bi(tests_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-ii)** <br> {points: 2}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` failed?      \n",
    "*Assign the correct answer to an object called `tests_failed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a651b9fbb2e7b2a5b7300f40a4241b3f",
     "grade": false,
     "grade_id": "cell-1202fc67d62b1792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_failed = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b81476073bd44de4e8817f9093fb0d",
     "grade": true,
     "grade_id": "cell-abcdd5212ce8810c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-iii)** <br> {points: 1}  \n",
    "\n",
    "Name a test that did not pass.   \n",
    "*Assign the correct answer to an object called `failed_name`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18a537e1b9d742949bb3e75ecaa94a9",
     "grade": false,
     "grade_id": "cell-67209bf44bc4b370",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "failed_name = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0480cd9b22932ceeef90d6c2fb046aa5",
     "grade": true,
     "grade_id": "cell-3d2823a898a6289a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_3biii(failed_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Black and Flake8 Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a)** <br>\n",
    "\n",
    "Run Flake8 on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling.py:4:43: E251 unexpected spaces around keyword / parameter equals\r\n",
      "sampling.py:4:45: E251 unexpected spaces around keyword / parameter equals\r\n",
      "sampling.py:8:1: W293 blank line contains whitespace\r\n",
      "sampling.py:18:1: W293 blank line contains whitespace\r\n",
      "sampling.py:23:1: W293 blank line contains whitespace\r\n",
      "sampling.py:31:1: W293 blank line contains whitespace\r\n",
      "sampling.py:33:1: W293 blank line contains whitespace\r\n",
      "sampling.py:35:1: W293 blank line contains whitespace\r\n",
      "sampling.py:36:35: W291 trailing whitespace\r\n",
      "sampling.py:37:25: E222 multiple spaces after operator\r\n",
      "sampling.py:39:1: W293 blank line contains whitespace\r\n",
      "sampling.py:41:1: W391 blank line at end of file\r\n"
     ]
    }
   ],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-i)** <br> {points: 1}  \n",
    "\n",
    "How many formatting issues did flake8 recognize in the `sampling.py` file?      \n",
    "*Assign the correct answer to an object called `answer4_ai`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d4970e87ebc89bbab5933e526bc9d56",
     "grade": false,
     "grade_id": "cell-27db9cfd0445f2ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_ai = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9cedde3d5ecbc3f9cff73e87bc888b",
     "grade": true,
     "grade_id": "cell-da78b4046f2a5291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4ai(answer4_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-ii)** <br> {points: 1}  \n",
    "\n",
    "How many `W291 trailing whitespace` issues are there? (We will talk a little bit about trailing and leading white space in Module 8)       \n",
    "*Assign the correct answer to an object called `answer4_aii`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a12ea403bfdb2232c6d38b8c1b077c5",
     "grade": false,
     "grade_id": "cell-4380df8c2f16c985",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aii = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69531d3d00c1ce4dbdac5fb7d33de02e",
     "grade": true,
     "grade_id": "cell-ab23a0ce59a092f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4aii(answer4_aii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-iii)** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Which of the following is the formatting issue that occurs on line 36?     \n",
    "\n",
    "\n",
    "A) `E222 multiple spaces after operator`\n",
    "\n",
    "B) `W293 blank line contains whitespace`\n",
    "\n",
    "C) `W291 trailing whitespace`\n",
    "\n",
    "D) `E251 unexpected spaces around keyword / parameter equals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_aiii`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8ba94996c89f41c55e0462426fde910",
     "grade": false,
     "grade_id": "cell-4cdb5bce57b584a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aiii = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8d3aab045252b408d7476ca95207e2",
     "grade": true,
     "grade_id": "cell-7775bd41eaf54724",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4aiii(answer4_aiii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(b)**  {points: 1}  \n",
    "\n",
    "Run `black` on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to run black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which code would you use in a Jupyter code cell to run Black?\n",
    "\n",
    "A) `black sampling.py`\n",
    "\n",
    "B) `!black sampling.py` \n",
    "\n",
    "C) `sampling.black()`\n",
    "\n",
    "D) `black.sampling()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_b`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84c9e855c345eac9d7fd09bd3f7f8c1f",
     "grade": false,
     "grade_id": "cell-10e4f5655e22c244",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_b = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76e0feef20e3e846229cb069767abe38",
     "grade": true,
     "grade_id": "cell-c9348b9faa589abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_4b(answer4_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(c)** <br> {points: 2}  \n",
    "\n",
    "Now that we have reformatted our `sampling.py` file, let's rerun flake8 just as we did before as see how many of our formatting issues have been fixed and answer the question below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to run flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many formatting issues are we left with after re-runing flake8 after formatting `sampling.py` using the `black` style guide?\n",
    "\n",
    "*Assign the correct answer to an object called `answer4_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bee54132eb4c6c8c098d8c36a9eabec",
     "grade": false,
     "grade_id": "cell-a94532cb877f86ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602952b54c4dc96a00ec19e3e1b64280",
     "grade": true,
     "grade_id": "cell-b9a92e7037aad0c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Style Guide - Comments and Variable Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(a)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is most fitting for an object that contains a list of column names from a dataframe named `metals`? \n",
    "\n",
    "A) `metal_columns`\n",
    "\n",
    "B) `columnsfrommetaldataframe`\n",
    "\n",
    "C) `list`\n",
    "\n",
    "D) `c_metals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_a`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea99287d09106ebc9636ea5fdb831838",
     "grade": false,
     "grade_id": "cell-f50baa637608027f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_a = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f4cacdab2a71d36acc7317f216f4a80",
     "grade": true,
     "grade_id": "cell-141b5df587a3cc3e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5a(answer5_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(b)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is the best fitting for object containing a dataframe containing different lightbulb types?\n",
    "\n",
    "A) `LIGHTBULBS`\n",
    "\n",
    "B) `dataframe_where_lightbulbs_data_stored`\n",
    "\n",
    "C) `data`\n",
    "\n",
    "D) `lightbulb_df` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_b`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efffe815faf74591e38eb4b46312af57",
     "grade": false,
     "grade_id": "cell-1ac2beeec7f1258d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_b = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2d999013dd895239cbf204bb401bb5f",
     "grade": true,
     "grade_id": "cell-5a33f1e90db1379f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5b(answer5_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(c)** <br> {points: 2}  \n",
    "\n",
    "Which of the following is NOT a reasonable comment to include in your code?\n",
    "\n",
    "A) `# Keep this line of code in, or the function will break mysteriously`\n",
    "\n",
    "B) `# Rename columns to shorter column names`\n",
    "\n",
    "C) `# This assigns all the values greater than 100 a value of 100.`\n",
    "\n",
    "D) `# TODO: Fix this next part so it's more readable and doesn't include magic numbers` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b780f05c3efad8ea5202822858169d",
     "grade": false,
     "grade_id": "cell-58ce14551039cefd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_c = None\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc374f8eae271b873f35ee34826fc662",
     "grade": true,
     "grade_id": "cell-67d88876daa123c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(d)** <br> {points: 2}  \n",
    "\n",
    "Below is a function that plots a histogram of a specified quantitative column.\n",
    "We want you to identify the 4 poorly designed elements within this function, and rewrite/rename them to something that is more appropriate. \n",
    "\n",
    "Copy and paste the function into the cell that follows it and then make your desired changes.\n",
    "\n",
    "*Hint: The function name does not need to be changed* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def column_histogram(data, column_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to filter\n",
    "    column_name : str\n",
    "        The column values to plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v4.api.Chart \n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.vegalite.v4.api.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    # This checks if the data variable is of type pd.dataframe\n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # This area is reserved for an exception which checks the column dtype of column_name, it could be useful\n",
    "    \n",
    "    cs = column_name + \":Q\"\n",
    "    \n",
    "    # This makes a histogram and plots the values of column_name frequency \n",
    "    histogram_plot_of_column_name = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X( cs, bin=True),\n",
    "                                              y='count()',\n",
    "                                    )\n",
    "    \n",
    "    # This function now returns a histogram \n",
    "    return histogram_plot_of_column_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d4f1778c613d7ac02986673ef33e5d",
     "grade": false,
     "grade_id": "cell-4e57ff3c843e88ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87ea3309c00598248532b21c9aec546",
     "grade": true,
     "grade_id": "cell-c8c1a1322f269763",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5d(column_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- UBC's original STAT545 - [Stat545 by Jenny Bryan](https://stat545.com/)\n",
    "- MDS DSCI 523 - Data Wrangling course - [MDS's GitHub website](hhttps://ubc-mds.github.io/) \n",
    "- Chopped Dataset - [Kaggle](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Debriefing\n",
    "\n",
    "If this video is not showing up below, click on the cell and click the ▶ button in the toolbar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('hBGFNWtYoYw', width=854, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
